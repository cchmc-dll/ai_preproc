{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\somd7w\\\\Desktop\\\\DL_Projects\\\\preproc_cntr\\\\output'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set Working Dir\n",
    "import os\n",
    "os.chdir('C:\\\\Users\\\\somd7w\\\\Desktop\\\\DL_Projects\\\\preproc_cntr\\\\output')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datafile\n",
    "data_file='data_32_final.h5'\n",
    "import tables\n",
    "hdf5_file = tables.open_file(data_file, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split list based on split fraction\n",
    "from random import shuffle\n",
    "\n",
    "def split_list(input_list, split=0.8, shuffle_list=True):\n",
    "    if shuffle_list:\n",
    "        shuffle(input_list)\n",
    "    n_training = int(len(input_list) * split)\n",
    "    training = input_list[:n_training]\n",
    "    testing = input_list[n_training:]\n",
    "    return training, testing\n",
    "\n",
    "# Function to Save Pickle file\n",
    "import pickle\n",
    "\n",
    "def pickle_dump(item, out_file):\n",
    "    with open(out_file, \"wb\") as opened_file:\n",
    "        pickle.dump(item, opened_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUmber of samples in Training: 578\n",
      "NUmber of samples in Test: 144\n"
     ]
    }
   ],
   "source": [
    "# Split data file into Train and Test\n",
    "test_split = 0.20\n",
    "nb_samples = hdf5_file.root.subject_ids.shape[0]\n",
    "sample_list = list(range(nb_samples))\n",
    "test_list, training_list = split_list(sample_list, split=test_split)\n",
    "print(\"NUmber of samples in Training:\", len(training_list))\n",
    "print(\"NUmber of samples in Test:\", len(test_list))\n",
    "training_file = 'train_'+str(len(training_list))+'.pkl'\n",
    "test_file = 'test_'+str(len(test_list))+'.pkl'\n",
    "pickle_dump(training_list, training_file)\n",
    "pickle_dump(test_list, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "KFold(n_splits=5, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "# USE for sklearn k-fold Cross Validation Split of training list into train and validation\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "#X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]]) # create an array\n",
    "#y = np.array([1, 2, 3, 4]) # Create another array\n",
    "X = training_list\n",
    "kf = KFold(n_splits=5) # Define the split - into 2 folds \n",
    "print(kf.get_n_splits(X)) # returns the number of splitting iterations in the cross-validator\n",
    "print(kf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1 Train file:  train_fold_1_462.pkl validation file:  valid_fold_1_116.pkl\n",
      "Fold:  2 Train file:  train_fold_2_462.pkl validation file:  valid_fold_2_116.pkl\n",
      "Fold:  3 Train file:  train_fold_3_462.pkl validation file:  valid_fold_3_116.pkl\n",
      "Fold:  4 Train file:  train_fold_4_463.pkl validation file:  valid_fold_4_115.pkl\n",
      "Fold:  5 Train file:  train_fold_5_463.pkl validation file:  valid_fold_5_115.pkl\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "for train_index, val_index in kf.split(X):\n",
    "    fold = fold+1\n",
    "    #print(\"TRAIN:\", len(train_index), \"TEST:\", len(val_index))\n",
    "    train_file = 'train_fold_'+str(fold)+'_'+str(len(train_index))+'.pkl'\n",
    "    val_file = 'valid_fold_'+str(fold)+'_'+str(len(val_index))+'.pkl'\n",
    "    pickle_dump(train_index,train_file)\n",
    "    pickle_dump(val_index,val_file)\n",
    "    print(\"Fold: \",fold, \"Train file: \",train_file, \"validation file: \", val_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
